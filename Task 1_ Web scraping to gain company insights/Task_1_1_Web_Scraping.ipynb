{"cells":[{"source":"# Task 1: Web scraping ","metadata":{},"id":"fb10fc45-b18c-4b5e-90af-6299628b2e22","cell_type":"markdown"},{"source":"## Step 01 : importing libraries","metadata":{},"id":"e66a448c-a84b-4f69-b00c-0d4236978540","cell_type":"markdown"},{"source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd","metadata":{"executionCancelledAt":null,"executionTime":142,"lastExecutedAt":1711923074469,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd"},"id":"07892d26-edf0-4000-a977-b39830bd74fc","cell_type":"code","execution_count":6,"outputs":[]},{"source":"## Step 02 : setup for the scraping ","metadata":{},"id":"641341fc-9c69-4749-b062-eb080c853ee8","cell_type":"markdown"},{"source":"# since we want to import the reviews about british airways we'll visit the website called \"airlinequality\" and search \"british airways \" and use that link \nbase_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\npages = 10 \npage_size = 100\n\nreviews = []","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1711923322185,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# since we want to import the reviews about british airways we'll visit the website called \"airlinequality\" and search \"british airways \" and use that link \nbase_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\npages = 10 \npage_size = 100\n\nreviews = []"},"id":"5256360d-29e5-4cee-8064-9d766ca2366c","cell_type":"code","execution_count":7,"outputs":[]},{"source":"## Step 03 : collecting the data","metadata":{},"id":"eb7ac214-c051-49ab-8193-b9e1470fb4e6","cell_type":"markdown"},{"source":"for i in range(1, pages + 1):\n    print(\"we're scraping page number \" , i )\n    # we notice that the link of second page is \"https://www.airlinequality.com/airline-reviews/british-airways/page/2/?sortby=post_date%3ADesc&pagesize=100\" we can generalize this link to collect all coming links 'Navigate through pages ' \n    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n    # we start collecting html data \n    response = requests.get(url)\n    \n    #parsing the content\n    content = response.content\n    parsed_content = BeautifulSoup(content, 'html.parser')\n    for par in parsed_content.find_all(\"div\", {'class' : 'text_content'}):\n        reviews.append(par.get_text())\n    print(f\"   ---> {len(reviews)} total reviews\")","metadata":{"executionCancelledAt":null,"executionTime":15952,"lastExecutedAt":1711923956921,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"for i in range(1, pages + 1):\n    print(\"we're scraping page number \" , i )\n    # we notice that the link of second page is \"https://www.airlinequality.com/airline-reviews/british-airways/page/2/?sortby=post_date%3ADesc&pagesize=100\" we can generalize this link to collect all coming links 'Navigate through pages ' \n    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n    # we start collecting html data \n    response = requests.get(url)\n    \n    #parsing the content\n    content = response.content\n    parsed_content = BeautifulSoup(content, 'html.parser')\n    for par in parsed_content.find_all(\"div\", {'class' : 'text_content'}):\n        reviews.append(par.get_text())\n    print(f\"   ---> {len(reviews)} total reviews\")","outputsMetadata":{"0":{"height":570,"type":"stream"}}},"id":"93dd82dc-cba5-452a-b9fe-332a28e49197","cell_type":"code","execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":["we're scraping page number  1\n","   ---> 100 total reviews\n","we're scraping page number  2\n","   ---> 200 total reviews\n","we're scraping page number  3\n","   ---> 300 total reviews\n","we're scraping page number  4\n","   ---> 400 total reviews\n","we're scraping page number  5\n","   ---> 500 total reviews\n","we're scraping page number  6\n","   ---> 600 total reviews\n","we're scraping page number  7\n","   ---> 700 total reviews\n","we're scraping page number  8\n","   ---> 800 total reviews\n","we're scraping page number  9\n","   ---> 900 total reviews\n","we're scraping page number  10\n","   ---> 1000 total reviews\n"]}]},{"source":"## Step 04 : saving results in a dataframe","metadata":{},"id":"438c7fb5-f482-4671-8061-6483b825577f","cell_type":"markdown"},{"source":"df = pd.DataFrame()\ndf['reviews'] = reviews\ndf.head()","metadata":{"executionCancelledAt":null,"executionTime":22,"lastExecutedAt":1711924028456,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"df = pd.DataFrame()\ndf['reviews'] = reviews\ndf.head()","outputsMetadata":{"0":{"height":198,"type":"dataFrame"}}},"id":"cf36d882-4f31-4270-9852-f8abda174d8d","cell_type":"code","execution_count":9,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>reviews</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Not Verified |  I flew internationally for the...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>✅ Trip Verified | BA, after subsequent delays ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Not Verified |   It is embarrassing to have th...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>✅ Trip Verified | Flight cancelled due to bad ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>✅ Trip Verified |  British Airways oversold my...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             reviews\n","0  Not Verified |  I flew internationally for the...\n","1  ✅ Trip Verified | BA, after subsequent delays ...\n","2  Not Verified |   It is embarrassing to have th...\n","3  ✅ Trip Verified | Flight cancelled due to bad ...\n","4  ✅ Trip Verified |  British Airways oversold my..."]},"execution_count":9,"metadata":{},"output_type":"execute_result"}]},{"source":"## Step 05 : saving df to csv file","metadata":{},"id":"bd6d1c63-15d4-4e80-ab5f-4b2a1cae9171","cell_type":"markdown"},{"source":"df.to_csv('British_Airways_reviews.csv')","metadata":{"executionCancelledAt":null,"executionTime":72,"lastExecutedAt":1711924097238,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"df.to_csv('British_Airways_reviews')"},"id":"3c108554-c527-4566-a964-5c2bfb2bd083","cell_type":"code","execution_count":10,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":5}